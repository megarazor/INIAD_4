{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "qualified-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "military-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_in = 'dm-mid-p4.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "representative-portugal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tryna work with some rappers check out the one...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eminem is the greatest artist to ever touch th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if u love rihanna subscribe me</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best rap everï»¿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e.e....everyone could check out my channel.. d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  CLASS\n",
       "0  tryna work with some rappers check out the one...      1\n",
       "1  Eminem is the greatest artist to ever touch th...      0\n",
       "2                     if u love rihanna subscribe me      1\n",
       "3                                   best rap everï»¿      0\n",
       "4  e.e....everyone could check out my channel.. d...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 448 entries, 0 to 447\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   CONTENT  448 non-null    object\n",
      " 1   CLASS    448 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(csv_in, delimiter=',', skiprows=0, header=0, encoding='latin-1')\n",
    "print(df.shape)\n",
    "display(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "behavioral-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "380    Maybe no one will probably read this. But just...\n",
       "11     Also check out D.j.j where do i go now and roa...\n",
       "173    MEGAN FOX AND EMINEM TOGETHER IN A VIDEO Â DOE...\n",
       "379               Check out this playlist on YouTube:ï»¿\n",
       "290               She looks like Megan FoxÂ ð xD!!ï»¿\n",
       "Name: CONTENT, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "236          We need to get this to 1 Billion Views!!ï»¿\n",
       "303                                              loveï»¿\n",
       "308    He is good boy!!!<br />I am krean I like to em...\n",
       "280                                                BRï»¿\n",
       "78     My friends wife earns 4000DOLLARS a month ,you...\n",
       "Name: CONTENT, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "380    1\n",
       "11     1\n",
       "173    0\n",
       "379    1\n",
       "290    0\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "236    0\n",
       "303    0\n",
       "308    0\n",
       "280    0\n",
       "78     1\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train, df_test= train_test_split(df, test_size=0.30, random_state=62)\n",
    "X_train= df_train['CONTENT']\n",
    "X_test= df_test['CONTENT']\n",
    "y_train= df_train['CLASS']\n",
    "y_test= df_test['CLASS']\n",
    "\n",
    "print(X_train.shape)\n",
    "display(X_train.head())\n",
    "\n",
    "print(X_test.shape)\n",
    "display(X_test.head())\n",
    "\n",
    "print(y_train.shape)\n",
    "display(y_train.head())\n",
    "\n",
    "print(y_test.shape)\n",
    "display(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "august-economy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1318\n",
      "['00', '000', '10', '100', '1000', '100877300245414', '11', '12year', '1337', '14', '15', '16', '17yr', '18', '1990', '1b', '1billion', '200', '2005', '2008', '2010', '2013', '2014', '2015', '2015ï', '21', '23awesome', '23eminem', '23king', '23lovethewayyoulie', '23rapgod', '23rt', '23share', '25', '2asfn9shghk', '2b4wywphi8c', '2zme8f', '31st', '365', '36loseweight', '39', '3rd', '3ï', '4000', '41', '447935454150', '46', '482', '4eï', '4th', '50', '500k', '60', '6_h0m5sayho', '7k', '800', '857', '87', '90', '940', 'ablaze', 'about', 'absolutely', 'abuses', 'abusive', 'abusue', 'acaer', 'acceptance', 'accidental', 'accomplished', 'achieve', 'activates', 'actual', 'actually', 'ad', 'adam', 'adapt', 'adhoc', 'adult', 'advance', 'afraid', 'aftermath', 'again', 'ago', 'agree', 'agreeable', 'aimbwbfqbzg', 'album', 'alcoholic', 'alive', 'all', 'almost', 'aloidia', 'already', 'alright', 'also', 'always', 'am', 'amazing', 'amazon', 'american', 'amount', 'amp', 'an', 'analyst', 'and', 'andrew', 'annoying', 'annoys', 'answer', 'any', 'anybody', 'anyone', 'apologies', 'appreciate', 'appreciated', 'are', 'arkglzjqup0', 'arrowgance', 'artist', 'as', 'ask', 'asking', 'aslamu', 'aspiring', 'aswell', 'at', 'attacks', 'attention', 'audio', 'australia', 'authenticviews', 'authority', 'awards', 'aware', 'away', 'awesome', 'awesoooome', 'axiomatic', 'aye', 'ayyy', 'azerbaijan', 'back', 'bad', 'bands', 'bangladesh', 'bars', 'base', 'basically', 'basketball', 'be', 'beat', 'beating', 'beats', 'beautiful', 'because', 'become', 'been', 'before', 'belgium', 'believe', 'belle', 'berzerk', 'besloor', 'best', 'better', 'betterï', 'between', 'beware', 'bieber', 'big', 'billionï', 'bit', 'bite', 'black', 'blast', 'bless', 'blogspot', 'blows', 'blushing', 'boaconic', 'bocilile', 'book', 'bored', 'bottom', 'bout', 'boy', 'boys', 'br', 'brand', 'brazil', 'breaken', 'breaks', 'briefs', 'bring', 'brings', 'broken', 'brother', 'brutally', 'btw', 'buchmair', 'build', 'bulgariaï', 'burst', 'business', 'busyglide', 'but', 'button', 'by', 'called', 'came', 'can', 'canibus', 'canvas', 'case', 'catch', 'categories', 'cazzy', 'celeb', 'cent', 'certain', 'challenge', 'chance', 'chanel', 'channel', 'chansonï', 'charley', 'charlie', 'chcfcvzfzfbvzdrï', 'cheat', 'cheating', 'check', 'cheilith', 'chesture', 'children', 'chillpal', 'choice', 'chooses', 'chorenn', 'chrck', 'christmas', 'chubby', 'claire', 'class', 'classsic', 'claster', 'clean', 'click', 'clip', 'clipï', 'closer', 'coffee', 'cold', 'collaboration', 'columbus', 'column', 'com', 'come', 'comeing', 'coming', 'comment', 'comments', 'commit', 'commment', 'competition', 'congratulations', 'constructive', 'conveying', 'cook', 'cool', 'coolï', 'cope', 'could', 'country', 'counts', 'cover', 'covered', 'covers', 'crabby', 'crap', 'crazy', 'crimes', 'criminals', 'criticism', 'critisism', 'crown', 'crush', 'cruz', 'cry', 'cudi', 'cypher', 'cyphers', 'dad', 'daily', 'dakota', 'damn', 'damnï', 'dance', 'dante', 'dated', 'day', 'days', 'death', 'deazy99', 'decent', 'dedicated', 'delicate', 'delightful', 'depreciateds', 'derives', 'deserves', 'desire', 'details', 'devils', 'did', 'didnt', 'die', 'disappoint', 'disguise', 'distribution', 'dna', 'do', 'does', 'doesn', 'doesnt', 'doing', 'domestic', 'don', 'done', 'dongs', 'dont', 'dope', 'down', 'download', 'dream', 'dreams', 'drews', 'drirathiel', 'driveshaftï', 'drop', 'drugs', 'dude', 'duo', 'dï', 'eager', 'earned', 'easy', 'economic', 'edit', 'effect', 'eggmode', 'elevator', 'else', 'em', 'eminem', 'eminems', 'eminemï', 'eminenï', 'emotions', 'emä', 'encouraging', 'end', 'ended', 'ends', 'energy', 'english', 'enjoy', 'enough', 'enter', 'entertainment', 'entertains', 'ep', 'equipment', 'especially', 'et', 'eu', 'even', 'ever', 'every', 'everyday', 'everyone', 'everything', 'everï', 'evil', 'ex', 'exactly', 'exciting', 'exclusive', 'exist', 'expansion', 'exposes', 'exposure', 'extraordinary', 'facebook', 'fact', 'fair', 'fame', 'famous', 'fan', 'fans', 'fantasy', 'far', 'farrell', 'fast', 'fated', 'fav', 'favor', 'favorite', 'favour', 'favourite', 'favï', 'fb', 'feandra', 'fears', 'feature', 'featuring', 'feed', 'feedback', 'feel', 'feeling', 'feels', 'ferirama', 'fgw', 'fictional', 'find', 'fire', 'firepa', 'firms', 'first', 'five', 'flight', 'flow', 'follow', 'following', 'for', 'forever', 'foreverï', 'forgot', 'fort', 'found', 'four', 'fox', 'foxâ', 'foxï', 'freaking', 'free', 'freestyles', 'fresh', 'friend', 'from', 'fruits', 'ft', 'fuck', 'fuffapster', 'fullest', 'funny', 'game', 'gameplay', 'gangnam', 'gay', 'geezeï', 'george', 'get', 'gets', 'getting', 'ginius', 'girl', 'girls', 'give', 'gives', 'go', 'god', 'godï', 'gogopo', 'going', 'gonna', 'good', 'goodï', 'google', 'gorg', 'gorgeous', 'got', 'great', 'greatest', 'greatï', 'greenï', 'groups', 'growing', 'gt', 'gta', 'guasch', 'guss', 'guy', 'guys', 'hack', 'hack2013', 'hacking', 'had', 'haha', 'hair', 'hand', 'handsome', 'happy', 'harbor', 'hard', 'harts', 'has', 'hashtag', 'hate', 'haters', 'have', 'hay', 'he', 'head', 'health', 'hear', 'heard', 'heart', 'hell', 'hello', 'help', 'helping', 'helpless', 'helps', 'her', 'here', 'hermann', 'heroin', 'hes', 'hey', 'hi', 'high', 'hilarious', 'him', 'hioffpo', 'hip', 'hiphop', 'his', 'historyï', 'hit', 'holy', 'home', 'homies', 'honesty', 'hood', 'hop', 'hope', 'hopes', 'hoppler', 'horrific', 'hot', 'hotter', 'hotï', 'how', 'href', 'http', 'https', 'huh', 'humor', 'hurts', 'hyuck', 'ideas', 'idiotic', 'idol', 'if', 'ignore', 'ill', 'illustrate', 'im', 'imperfect', 'improve', 'improves', 'in', 'inbox', 'including', 'increase', 'industry', 'ini', 'ink', 'innocent', 'insane', 'inside', 'insideï', 'insidious', 'insperasen', 'inspiration', 'intelligence', 'intelligent', 'internet', 'intervene', 'into', 'invest', 'is', 'island', 'isnt', 'it', 'its', 'itï', 'ive', 'iâ', 'jackson', 'jail', 'jamï', 'january', 'jelly', 'john', 'journey', 'judges', 'juss', 'just', 'justing', 'keen', 'keep', 'keithlinscotts', 'khalifa', 'kid', 'kids', 'kill', 'killtheclockhd', 'king', 'kingston', 'know', 'knowledge', 'known', 'ladies', 'lake', 'lane', 'language', 'lasting', 'latest', 'laugh', 'laughable', 'law', 'leandrus', 'learned', 'learning', 'leave', 'less', 'let', 'letting', 'lie', 'liers', 'lies', 'lieï', 'life', 'like', 'likes', 'likeï', 'lil', 'limit', 'line', 'link', 'linked', 'linz', 'listen', 'listening', 'little', 'live', 'lively', 'lives', 'living', 'll', 'lol', 'london', 'long', 'longer', 'look', 'looking', 'looks', 'looooved', 'losing', 'loss', 'lost', 'lostï', 'lot', 'loud', 'lova', 'love', 'lovely', 'lovers', 'loves', 'lovethewayyoulie', 'loveð', 'loving', 'lt', 'luckï', 'lulerain', 'lunden', 'luv', 'luxuriant', 'ly', 'lykum', 'lyric', 'lyrical', 'lyrically', 'lyricism', 'lyrics', 'made', 'magnificent', 'mail', 'mainstream', 'make', 'makeing', 'making', 'mammoth', 'man', 'many', 'master', 'may', 'maybe', 'mcashim', 'me', 'mean', 'means', 'meaty', 'media', 'megan', 'meghan', 'memory', 'mere', 'message', 'metal', 'method', 'meï', 'mic', 'micheal', 'might', 'mile', 'millions', 'mind', 'mine', 'minute', 'minutes', 'miss', 'missing', 'mission', 'misty', 'mix', 'mixing', 'mizuxe', 'mockingbird', 'moderock', 'modgone', 'mogotrevo', 'molly', 'moly', 'mom', 'moment', 'money', 'moneygq', 'monstrous', 'month', 'months', 'more', 'mosh', 'most', 'mother', 'motivate', 'mountain', 'much', 'muchâ', 'muchï', 'mummy', 'music', 'musicï', 'must', 'muzik', 'my', 'myself', 'name', 'named', 'naperone', 'narrow', 'nation', 'near', 'nearly', 'nearï', 'need', 'nelson', 'nem', 'net', 'never', 'new', 'news', 'next', 'nice', 'niceï', 'niko', 'nirvana', 'no', 'nofollow', 'noodile', 'normal', 'not', 'nothing', 'notice', 'notorious', 'now', 'number', 'ociramma', 'od', 'of', 'off', 'officiates', 'oh', 'oil', 'okay', 'old', 'oleald', 'olielle', 'omg', 'omniscient', 'on', 'one', 'online', 'only', 'operating', 'operation', 'opinion', 'opportunity', 'or', 'order', 'oreo', 'original', 'ot', 'others', 'our', 'out', 'over', 'ow', 'own', 'page', 'pakistanï', 'palastineï', 'paper', 'paragraph', 'parede', 'part', 'pass', 'passed', 'passion', 'password', 'past', 'peace', 'pen', 'people', 'pepelexa', 'per', 'perform', 'performance', 'performing', 'perpetrated', 'person', 'phenomenallyricshere', 'photo', 'picked', 'picture', 'pisses', 'place', 'plant', 'play', 'player', 'playlist', 'playtime', 'please', 'pleaseï', 'pleasureï', 'plese', 'plifal', 'ploosnar', 'pls', 'plus', 'plz', 'pmw', 'pn', 'pointers', 'police', 'polish', 'pop', 'popï', 'possible', 'post', 'potential', 'pour', 'power', 'press', 'prioritize', 'probable', 'probably', 'produced', 'professionally', 'professor', 'promise', 'protect', 'protective', 'psy', 'pun', 'push', 'pussy', 'put', 'qerrassa', 'qiameth', 'quadrillion', 'quality', 'quickest', 'quite', 'quot', 'rage', 'range', 'rap', 'rape', 'rapgod', 'rapped', 'rapper', 'rappers', 'rapping', 'rapï', 're', 'reach', 'read', 'reading', 'ready', 'real', 'realized', 'really', 'recentley', 'recently', 'record', 'recording', 'recovery', 'red', 'reduce', 'refers', 'reflective', 'regret', 'rehabilitate', 'reiltas', 'rel', 'released', 'remember', 'reminds', 'remix', 'remixes', 'render', 'repair', 'report', 'resort', 'response', 'responsible', 'reviews', 'rhianna', 'rhinnahï', 'rhymes', 'right', 'rihana', 'rihanna', 'rihannaï', 'riled', 'riri', 'road', 'roasted', 'rock', 'roll', 'roulette', 'rt', 'rule', 'ryhme', 'ryme', 'sad', 'same', 'sasaroo', 'say', 'scale', 'scare', 'screwing', 'sean', 'search', 'searchs', 'second', 'secret', 'see', 'selection', 'self', 'september', 'serious', 'seriously', 'sertave', 'serving', 'several', 'sexual', 'sexy', 'shady', 'shallow', 'shame', 'share', 'shared', 'shares', 'she', 'shes', 'shock', 'shorogyt', 'should', 'show', 'showï', 'sick', 'signed', 'similarï', 'simple', 'simply', 'since', 'sing', 'singer', 'single', 'singlewave', 'sister', 'site', 'skills', 'skip', 'skits', 'sky', 'skylar', 'smack', 'smaller', 'smoke', 'smoking', 'sneakiestg', 'sneeze', 'so', 'software', 'soldiers', 'some', 'someone', 'something', 'sometime', 'somewhere', 'song', 'songs', 'songï', 'soo', 'soon', 'sooooooooooooooo', 'sophisticated', 'sore', 'sorry', 'sounds', 'space', 'spam', 'spammed', 'spammers', 'spamming', 'speaks', 'special', 'speech', 'spell', 'spit', 'spourmo', 'spousal', 'stand', 'start', 'started', 'starting', 'stay', 'steel', 'still', 'stop', 'sttuupidï', 'stuff', 'style', 'sub', 'subs', 'subscribe', 'subscribed', 'subscribee', 'subscriber', 'subscribers', 'subscribing', 'subscrible', 'subscription', 'substantial', 'such', 'suck', 'suicide', 'supat', 'super', 'support', 'supporters', 'sure', 'surpassing', 'survival', 'swag', 'swear', 'swift', 'swoquix', 'symptomatic', 'synthesizes', 'take', 'takes', 'talents', 'talk', 'talking', 'tape', 'target', 'tax', 'taylor', 'tde', 'tell', 'tendency', 'terrance', 'texas', 'thailandâ', 'than', 'thank', 'thankfully', 'thanks', 'thanx', 'that', 'thatâ', 'thatï', 'the', 'the1fantasy', 'their', 'them', 'then', 'there', 'therealchrisking1', 'these', 'they', 'theyâ', 'things', 'think', 'this', 'those', 'thou', 'thought', 'thoughï', 'thumbs', 'time', 'times', 'timeï', 'title', 'titled', 'to', 'today', 'together', 'togetherï', 'told', 'tomorrow', 'tony', 'too', 'toogit', 'top', 'touch', 'towered', 'toy', 'toï', 'track', 'tracks', 'trailer', 'train', 'transmit', 'treating', 'trelod', 'tried', 'trigger', 'trop', 'true', 'truly', 'trust', 'trying', 'tryna', 'tube', 'tupacase', 'turned', 'tv', 'tvcmcadavid', 'tvï', 'twitter', 'two', 'tyga', 'type', 'uk', 'unbiased', 'uncovered', 'underground', 'understand', 'undesirable', 'unelind', 'unequaled', 'untitled', 'up', 'upcoming', 'uploaded', 'uppity', 'us', 'used', 'useless', 'user', 'usually', 'valuable', 'value', 've', 'vegetables', 'verse', 'verses', 'version', 'very', 'victorious', 'vid', 'video', 'videos', 'view', 'views', 'vincent', 'vines', 'violence', 'viral', 'virus', 'visit', 'vote', 'votre', 'walk', 'wanna', 'want', 'wanted', 'war', 'waratel', 'warning', 'was', 'wasn', 'wasnâ', 'waste', 'watch', 'watched', 'watching', 'way', 'ways', 'wazzasoft', 'we', 'weak', 'website', 'weebly', 'weekend', 'weight', 'welcome', 'well', 'were', 'what', 'wheels', 'when', 'where', 'while', 'whistleblower', 'white', 'whiz', 'who', 'whole', 'why', 'will', 'win', 'wind', 'wiry', 'wish', 'with', 'within', 'without', 'witnesss', 'woman', 'women', 'won', 'wonder', 'wonderfulï', 'wont', 'woozy', 'word', 'work', 'worked', 'working', 'works', 'world', 'worst', 'would', 'wouldnt', 'wright', 'write', 'writing', 'wrote', 'wtp', 'www', 'xd', 'xoxo', 'xxxï', 'xytcq5nzmua', 'ya', 'yboiveth', 'year', 'years', 'yesterday', 'yfuy4gkr1c', 'yo', 'yoffa', 'you', 'young', 'your', 'yourself', 'youtu', 'youtube', 'youtuber', 'youâ', 'youï', 'yrs', 'ytma', 'yuliya', 'yuttx04oyqq', 'zesty', 'zip', 'zonepa', 'ºmy', 'ºâ']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "vocab = vectorizer. get_feature_names()\n",
    "print('Vocabulary size:', len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "unsigned-hydrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_bow:\n",
      "<313x1318 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 4705 stored elements in Compressed Sparse Row format>\n",
      "X_test_bow:\n",
      "<135x1318 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 2033 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "X_train_bow = vectorizer.transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "print('X_train_bow:')\n",
    "print(repr(X_train_bow))\n",
    "print('X_test_bow:')\n",
    "print(repr(X_test_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "golden-profit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100877300245414</th>\n",
       "      <th>11</th>\n",
       "      <th>12year</th>\n",
       "      <th>1337</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>youï</th>\n",
       "      <th>yrs</th>\n",
       "      <th>ytma</th>\n",
       "      <th>yuliya</th>\n",
       "      <th>yuttx04oyqq</th>\n",
       "      <th>zesty</th>\n",
       "      <th>zip</th>\n",
       "      <th>zonepa</th>\n",
       "      <th>ºmy</th>\n",
       "      <th>ºâ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313 rows × 1318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  10  100  1000  100877300245414  11  12year  1337  14  ...  \\\n",
       "CLASS                                                                 ...   \n",
       "1       0    0   0    0     0                0   0       0     0   0  ...   \n",
       "1       0    0   0    0     0                0   0       0     0   0  ...   \n",
       "0       0    0   0    0     0                0   0       0     0   0  ...   \n",
       "1       0    0   0    0     0                0   0       0     0   0  ...   \n",
       "0       0    0   0    0     0                0   0       0     0   0  ...   \n",
       "...    ..  ...  ..  ...   ...              ...  ..     ...   ...  ..  ...   \n",
       "1       0    0   0    0     0                0   0       0     0   0  ...   \n",
       "1       0    0   0    0     0                0   0       0     0   0  ...   \n",
       "0       0    0   0    0     0                0   0       0     0   0  ...   \n",
       "1       0    0   0    0     0                0   0       0     0   0  ...   \n",
       "0       0    0   0    0     0                0   0       0     0   0  ...   \n",
       "\n",
       "       youï  yrs  ytma  yuliya  yuttx04oyqq  zesty  zip  zonepa  ºmy  ºâ  \n",
       "CLASS                                                                     \n",
       "1         0    0     0       0            0      0    0       0    0   0  \n",
       "1         0    0     0       0            0      0    0       0    0   0  \n",
       "0         0    0     0       0            0      0    0       0    0   0  \n",
       "1         0    0     0       0            0      0    0       0    0   0  \n",
       "0         0    0     0       0            0      0    0       0    0   0  \n",
       "...     ...  ...   ...     ...          ...    ...  ...     ...  ...  ..  \n",
       "1         0    0     0       0            0      0    0       0    0   0  \n",
       "1         0    0     0       0            0      0    0       0    0   0  \n",
       "0         0    0     0       0            0      0    0       0    0   0  \n",
       "1         0    0     0       0            0      0    0       0    0   0  \n",
       "0         0    0     0       0            0      0    0       0    0   0  \n",
       "\n",
       "[313 rows x 1318 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xbow = pd.DataFrame(X_train_bow.toarray(), \n",
    "                    index=y_train, columns=vocab)\n",
    "display(Xbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "conceptual-review",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "Train accuracy: 0.9680511182108626\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=1.0)\n",
    "model.fit(X_train_bow, y_train)\n",
    "print(model.classes_)\n",
    "train_score = model.score(X_train_bow, y_train)\n",
    "print('Train accuracy:', train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "supreme-truth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8296296296296296\n"
     ]
    }
   ],
   "source": [
    "train_score = model.score(X_test_bow, y_test)\n",
    "print('Test accuracy:', train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-antenna",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
